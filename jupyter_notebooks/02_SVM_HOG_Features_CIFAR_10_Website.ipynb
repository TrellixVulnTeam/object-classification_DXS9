{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3, linewidth=200, suppress=True)\n",
    "from library.datasets.cifar10 import CIFAR10\n",
    "from library.utils import file_utils\n",
    "from library.plot_tools import plot_tools\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split as train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import sklearn.metrics as skm\n",
    "from sklearn import svm\n",
    "from sklearn.externals import joblib\n",
    "import os, time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import toimage\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from library.hog.hog import HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_time = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_no = 101\n",
    "file_no = 2\n",
    "data_source = 'Website'\n",
    "train_validate_split = 0.2\n",
    "train_validate_split_data = None\n",
    "num_images_required = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_hot = True\n",
    "make_image = True\n",
    "mode='grey'\n",
    "scale_method = 'StandardScaler'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_name = 'exp_' + str(exp_no).zfill(3) + '_kernel_' + svm_kernel\n",
    "output_directory = '../logs/cifar10/' + str(file_no).zfill(2) + '_svm_hog/' + 'exp_no_' + str(exp_no).zfill(3) + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "block_size = (8,8)\n",
    "cell_size = (2,2)\n",
    "nbins = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_kernel = 'rbf'\n",
    "svm_gamma = 0.001\n",
    "svm_c = 10.0\n",
    "svm_max_iter = 10000\n",
    "svm_cs =1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.1: Load CIFAR 10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "cifar10 = CIFAR10(one_hot_encode=one_hot, num_images=num_images_required, make_image=make_image, image_mode=mode,\n",
    "                  train_validate_split=train_validate_split_data, endian='little')\n",
    "cifar10.load_data(train=True, test=True, data_directory='./datasets/cifar10/')\n",
    "end = time.time()\n",
    "print('[ Step 0] Dataset loaded in %5.6f ms' %((end-start)*1000))\n",
    "print('Dataset size: ' + str(cifar10.train.data.shape))\n",
    "num_train_images = cifar10.train.data.shape[0]\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Train data shape:', cifar10.train.data.shape)\n",
    "if one_hot is True:\n",
    "    print('Train labels shape:', cifar10.train.one_hot_labels.shape)\n",
    "if make_image is True:\n",
    "    print('Train images shape:', cifar10.train.images.shape)\n",
    "print('Train class labels shape:', cifar10.train.class_labels.shape)\n",
    "if train_validate_split_data is not None:\n",
    "    print('Validate data shape:', cifar10.validate.data.shape)\n",
    "    if one_hot is True:\n",
    "        print('Validate labels shape:', cifar10.validate.one_hot_labels.shape)\n",
    "    if make_image is True:\n",
    "        print('Validate images shape:', cifar10.vaidate.images.shape)\n",
    "    print('Validate class labels shape:', cifar10.validate.class_labels.shape)\n",
    "print('Test data shape:', cifar10.test.data.shape)\n",
    "if one_hot is True:\n",
    "    print('Test labels shape:', cifar10.test.one_hot_labels.shape)\n",
    "if make_image is True:\n",
    "    print('Test images shape:', cifar10.test.images.shape)\n",
    "print('Test class labels shape:', cifar10.test.class_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Training images')\n",
    "print(cifar10.train.data[:5])\n",
    "if make_image is True and mode=='rgb':\n",
    "    print('Training images rgb')\n",
    "    print(cifar10.train.images[:5])\n",
    "if make_image is True and mode=='float':\n",
    "    print('Training images float')\n",
    "    print(cifar10.train.images[:5])\n",
    "if one_hot is True:\n",
    "    print('Training labels')\n",
    "    print(cifar10.train.one_hot_labels[:5])\n",
    "print('Training classes')\n",
    "print(cifar10.train.class_labels[:5])\n",
    "print('Testing images')\n",
    "print(cifar10.test.data[:5])\n",
    "if make_image is True and mode=='rgb':\n",
    "    print('Testing images rgb')\n",
    "    print(cifar10.test.images[:5])\n",
    "if make_image is True and mode=='float':\n",
    "    print('Testing images float')\n",
    "    print(cifar10.test.images[:5])\n",
    "if one_hot is True:\n",
    "    print('Testing labels')\n",
    "    print(cifar10.test.one_hot_labels[:5])\n",
    "print('Testing classes')\n",
    "print(cifar10.test.class_labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.2: Load CIFAR 10 HOG Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "data_hog = []\n",
    "feature_size = 0\n",
    "hog = HOG(block_size=block_size, cell_size=cell_size, nbins=nbins)\n",
    "print('Generating HOG features for %d data images' %cifar10.train.images.shape[0])\n",
    "for fig_num in range(cifar10.train.images.shape[0]):\n",
    "    img = cifar10.train.images[fig_num, :]\n",
    "    gradients = hog.make_hog_gradients(img.astype('uint8'))\n",
    "    data_hog.append(gradients.flatten())\n",
    "    feature_size = gradients.size\n",
    "data_hog = np.array(data_hog)\n",
    "print('HOG Features for data: ' + str(data_hog.shape))\n",
    "end = time.time()\n",
    "print('Generated HOG for train images in %.6f ms' %((end-start)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.3: Load CIFAR 10 HOG Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "test_hog = []\n",
    "feature_size = 0\n",
    "print('Generating HOG features for %d test images' %cifar10.test.images.shape[0])\n",
    "for fig_num in range(cifar10.test.images.shape[0]):\n",
    "    img = cifar10.test.images[fig_num, :]\n",
    "    gradients = hog.make_hog_gradients(img.astype('uint8'))\n",
    "    test_hog.append(gradients.flatten())\n",
    "    feature_size = gradients.size\n",
    "test_hog = np.array(test_hog)\n",
    "print('HOG Features for test: ' + str(test_hog.shape))\n",
    "end = time.time()\n",
    "print('Generated HOG for test images in %.6f ms' %((end-start)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.4 Display an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cifar10.plot_sample(plot_data=True, plot_test=True, fig_size=(7, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cifar10.plot_images(cifar10.train.data[:50, :], cifar10.train.class_names[:50], \n",
    "                    nrows=5, ncols=10, fig_size=(20,50), fontsize=35, convert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "if scale_method == 'StandardScaler':\n",
    "    ss = StandardScaler()\n",
    "elif scale_method == 'MinMaxScaler':\n",
    "    ss = MinMaxScaler()\n",
    "else:\n",
    "    ss = StandardScaler()\n",
    "data_images = ss.fit_transform(data_hog)\n",
    "test_images = ss.fit_transform(test_hog)\n",
    "end = time.time()\n",
    "print('[ Step 2] Dataset transformations done in %.6f ms' %((end-start)*1000))\n",
    "print('Training the classifier on %d images' % num_train_images)\n",
    "print('Dataset size: ' + str(cifar10.train.data.shape))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train Test Split of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_images, cifar10.train.class_labels, \n",
    "                                                    test_size=train_validate_split)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "print('Train set shape         : ' + str(X_train.shape))\n",
    "print('Train labels shape      : ' + str(y_train.shape))\n",
    "print('Validation set shape    : ' + str(X_test.shape))\n",
    "print('Validation labels shape : ' + str(y_test.shape))\n",
    "end = time.time()\n",
    "print('[ Step 3] Train-test split done in %.6f ms' %((end-start)*1000))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Initiate Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "clf = svm.SVC(kernel=svm_kernel, C=svm_c, verbose=True, max_iter=svm_max_iter, cache_size=svm_cs, gamma=svm_gamma)\n",
    "print(clf)\n",
    "end = time.time()\n",
    "print('[ Step 4] Made the SVM classifier in %.6f ms' %((end-start)*1000))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate the SVC Model using the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "clf.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print('[ Step 5] Made the model in %.6f ms' %((end-start)*1000))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Write the obtained model to file for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "file_utils.mkdir_p(output_directory)\n",
    "model_output_path = output_directory + '02_' + param_name + '.pkl'\n",
    "joblib.dump(clf, model_output_path)\n",
    "end = time.time()\n",
    "print('[ Step 6] Write obtained model to %s in %.6f ms' %(model_output_path, ((end-start)*1000)))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Do the prediction on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test)\n",
    "labels = sorted(list(set(cifar10.train.class_labels)))\n",
    "print('Labels: ' + str(labels))\n",
    "plot_tools.plot_confusion_matrix(y_test, y_predict, classes=cifar10.classes, fig_size=(8,6),\n",
    "                              normalize=True, title='Confusion matrix for validation set with SVC')\n",
    "end = time.time()\n",
    "print('[ Step 7] Make prediction on validation dataset in %.6f ms' %((end-start)*1000))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Generate the Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print('Classification report:')\n",
    "print(skm.classification_report(y_test, y_predict, target_names=cifar10.classes))\n",
    "validate_accuracy = skm.accuracy_score(y_test, y_predict, normalize=True)\n",
    "print('Validation accuracy score: ' + str(validate_accuracy))\n",
    "end = time.time()\n",
    "print('[ Step 8] Generating classification on validation dataset in %.6f ms' %((end-start)*1000))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Generate the predictions on test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "prediction_numbers = clf.predict(test_images)\n",
    "prediction_classes = []\n",
    "num_test_images = test_hog.shape[0]\n",
    "for i in range(num_test_images):\n",
    "    prediction_classes.append(cifar10.classes[int(prediction_numbers[i])])\n",
    "end = time.time()\n",
    "print('[ Step 9] Make prediction on test dataset in %.6f ms' %((end-start)*1000))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cifar10.plot_images(cifar10.test.data[:50], cifar10.test.class_names[:50], cls_pred=prediction_classes[:50], \n",
    "                    nrows=5, ncols=10, fig_size=(20,50), fontsize=30, convert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Print the accuracy score of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "plot_tools.plot_confusion_matrix(cifar10.test.class_labels, prediction_numbers, classes=cifar10.classes,\n",
    "                              normalize=True, title='Confusion matrix for test set with SVC')\n",
    "print(skm.classification_report(cifar10.test.class_labels, prediction_numbers, target_names=cifar10.classes))\n",
    "test_accuracy = skm.accuracy_score(cifar10.test.class_labels, prediction_numbers, normalize=True)\n",
    "print('Accuracy score on test data: ' + str(test_accuracy))\n",
    "end = time.time()\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print('Prediction done on %d images' %test_images.shape[0])\n",
    "print('Accuracy of the classifier: %.4f' %clf.score(test_images, cifar10.test.class_labels))\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Write the predictions to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "indices = np.arange(1, test_images.shape[0]+1)\n",
    "predictions = np.column_stack((indices, prediction_classes))\n",
    "file_utils.mkdir_p(output_directory)\n",
    "output_csv_file = output_directory + '02_' + param_name + '.csv'\n",
    "column_names = ['id', 'label']\n",
    "predict_test_df = pd.DataFrame(data=predictions, columns=column_names)\n",
    "predict_test_df.to_csv(output_csv_file, index=False)\n",
    "end = time.time()\n",
    "print('[ Step 11] Writing the test data to file: %s in %.6f ms' %(output_csv_file, (end-start)*1000))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Code took %.6f s to run on training with %d examples' % (total_time,num_train_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the parameters for record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('| %d | ' %exp_no, end='')\n",
    "print('%d | '%num_train_images, end='')\n",
    "print('Kernel = %s, C = %.2f, Max. Iterations: %d, Cache size = %d, Random State: 1 | ' \n",
    "      %(svm_kernel, svm_c, svm_max_iter, svm_cs), end='')\n",
    "print('[Link](%s) | ' %output_csv_file, end='')\n",
    "print('%.4f | ' %validate_accuracy, end='')\n",
    "print('%.4f | ' %test_accuracy, end='')\n",
    "print('%s | ' %data_source, end='')\n",
    "print('[Link](%s) |' %model_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Write the notebook to HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_HTML(read_file, output_file):\n",
    "    from nbconvert import HTMLExporter\n",
    "    import codecs\n",
    "    import nbformat\n",
    "    exporter = HTMLExporter()\n",
    "    output_notebook = nbformat.read(read_file, as_version=4)\n",
    "    print()\n",
    "    output, resources = exporter.from_notebook_node(output_notebook)\n",
    "    codecs.open(output_file, 'w', encoding='utf-8').write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "var notebook = IPython.notebook\n",
    "notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_file = './' + theNotebook + '.ipynb'\n",
    "output_file = output_directory + str(file_no).zfill(2) + '_exp_no_' + str(exp_no) + '_' + theNotebook + '.html'\n",
    "print('Current file: ' + str(current_file))\n",
    "print('Output file: ' + str(output_file))\n",
    "file_utils.mkdir_p(output_directory) \n",
    "output_HTML(current_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Code took %.6f s to run on training with %d examples' % (total_time,num_train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
