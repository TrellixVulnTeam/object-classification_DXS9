{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reference : https://github.com/Hvass-Labs/TensorFlow-Tutorials\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "import prettytensor as pt\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load CIFAR10\n",
    "cifar_dir = \"./data/CIFAR-10/cifar-10-batches-py/\"\n",
    "cifar_train_cache = \"./data/CIFAR-10/inception_cifar10_train.pkl\"\n",
    "cifar_test_cache = \"./data/CIFAR-10/inception_cifar10_test.pkl\"\n",
    "train_sz = 50000\n",
    "test_sz = 10000\n",
    "img_sz = 32\n",
    "num_channels = 3\n",
    "num_classes = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(filename):\n",
    "    fpath = cifar_dir+filename\n",
    "    print(\"Loading \"+fpath)\n",
    "    file = open(fpath,mode='rb')\n",
    "    data = pickle.load(file, encoding='bytes')\n",
    "#     data = pickle.load(file, encoding='utf-8')\n",
    "    file.close()\n",
    "    return data\n",
    "\n",
    "def decode(filename):\n",
    "    data = unpickle(filename)\n",
    "    raw_images = data[b'data']\n",
    "    cls = np.array(data[b'labels'])\n",
    "    images = np.array(raw_images, dtype=float).reshape([-1, num_channels, img_sz, img_sz])\n",
    "    images = images.transpose([0, 2, 3, 1])\n",
    "    return images, cls\n",
    "\n",
    "def one_hotit(data):\n",
    "    return np.eye(num_classes, dtype=float)[data]\n",
    "\n",
    "def load_data():\n",
    "    print(\"Loading tarin data\")\n",
    "    train_images = np.zeros(shape=[train_sz, img_sz, img_sz, num_channels], dtype=float)\n",
    "    train_int_labels = np.zeros(shape=[train_sz], dtype=int)\n",
    "\n",
    "    begin = 0\n",
    "    for i in range(5):\n",
    "        data_file = \"data_batch_\"+str(i+1)\n",
    "        print(\"Loading \"+data_file)\n",
    "        images_batch, cls_batch = decode(data_file)\n",
    "        num_images = len(images_batch)\n",
    "        end = begin + num_images\n",
    "        train_images[begin:end, :] = images_batch\n",
    "        train_int_labels[begin:end] = cls_batch\n",
    "        begin = end\n",
    "        \n",
    "    print(\"Loading test data\")\n",
    "    test_images, test_int_labels = decode(\"test_batch\")\n",
    "    return train_images, train_int_labels, test_images, test_int_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tarin data\n",
      "Loading data_batch_1\n",
      "Loading ./data/CIFAR-10/cifar-10-batches-py/data_batch_1\n",
      "Loading data_batch_2\n",
      "Loading ./data/CIFAR-10/cifar-10-batches-py/data_batch_2\n",
      "Loading data_batch_3\n",
      "Loading ./data/CIFAR-10/cifar-10-batches-py/data_batch_3\n",
      "Loading data_batch_4\n",
      "Loading ./data/CIFAR-10/cifar-10-batches-py/data_batch_4\n",
      "Loading data_batch_5\n",
      "Loading ./data/CIFAR-10/cifar-10-batches-py/data_batch_5\n",
      "Loading test data\n",
      "Loading ./data/CIFAR-10/cifar-10-batches-py/test_batch\n"
     ]
    }
   ],
   "source": [
    "train_images, train_int_labels, test_images, test_int_labels = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = one_hotit(train_int_labels)\n",
    "test_labels = one_hotit(test_int_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./data/CIFAR-10/cifar-10-batches-py/batches.meta\n"
     ]
    }
   ],
   "source": [
    "metadata = unpickle(\"batches.meta\")[b'label_names']\n",
    "classnames = [x.decode('utf-8') for x in metadata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load inception model\n",
    "# Reference : https://github.com/Hvass-Labs/TensorFlow-Tutorials\n",
    "import inception\n",
    "from inception import transfer_values_cache\n",
    "model = inception.Inception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Data loaded from cache-file: ./data/CIFAR-10/inception_cifar10_train.pkl\n"
     ]
    }
   ],
   "source": [
    "train_transfer_values = transfer_values_cache(cache_path=cifar_train_cache , images=train_images, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Data loaded from cache-file: ./data/CIFAR-10/inception_cifar10_test.pkl\n"
     ]
    }
   ],
   "source": [
    "test_transfer_values = transfer_values_cache(cache_path=cifar_test_cache , images=test_images, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TF variables\n",
    "x = tf.placeholder(tf.float32, shape=[None, model.transfer_len], name='x')\n",
    "y_onehot = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_onehot')\n",
    "y_int = tf.argmax(y_onehot, dimension=1)\n",
    "\n",
    "\n",
    "# Neural Network\n",
    "x_pretty = pt.wrap(x)\n",
    "with pt.defaults_scope(activation_fn=tf.nn.relu):\n",
    "    y_pred, loss = x_pretty.\\\n",
    "    fully_connected(size=100, name='layer_fc1').\\\n",
    "    fully_connected(size=10, name='layer_fc2').\\\n",
    "    softmax_classifier(num_classes=num_classes, labels=y_onehot)\n",
    "\n",
    "# Optimizer and step counter\n",
    "global_step = tf.Variable(initial_value=0, name='global_step', trainable=False)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss, global_step)\n",
    "    \n",
    "# TF test \n",
    "ty_int = tf.argmax(y_pred, dimension=1)\n",
    "correct_prediction = tf.equal(y_int, ty_int)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256 # Change to limit RAM consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_batch():\n",
    "    idx = np.random.choice(train_sz, size=batch_size, replace=False)\n",
    "    x_batch = train_transfer_values[idx]\n",
    "    y_batch = train_labels[idx]\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(num_iterations):\n",
    "    tstart = time.time()\n",
    "    for i in range(num_iterations):\n",
    "        x_batch, y_batch = random_batch()\n",
    "        feed_dict_train = {x: x_batch, y_onehot: y_batch}\n",
    "        i_global,_ = session.run([global_step, optimizer], feed_dict=feed_dict_train)\n",
    "        if (i_global % 50 == 0) or (i == num_iterations - 1):\n",
    "            batch_acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "            msg = \"Global Step: {0:>6}, Training Batch Accuracy: {1:>6.1%}\"\n",
    "            print(msg.format(i_global, batch_acc))\n",
    "\n",
    "    tend = time.time()\n",
    "    diff = tend - tstart\n",
    "    print(\"Total time : \" + str(diff) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict():\n",
    "    pred = np.zeros(shape=test_sz, dtype=np.int)\n",
    "    i = 0\n",
    "    while i < test_sz:\n",
    "        j = min(i + batch_size, test_sz)\n",
    "        feed_dict = {x: test_transfer_values[i:j], y_onehot: test_labels[i:j]}\n",
    "        pred[i:j] = session.run(ty_int, feed_dict=feed_dict)\n",
    "        i = j\n",
    "    correct = (test_int_labels == pred)\n",
    "    return correct, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_confusion_matrix(cls_pred):\n",
    "    cm = confusion_matrix(y_true=test_int_labels, y_pred=cls_pred)\n",
    "    for i in range(num_classes):\n",
    "        # Append the class-name to each line.\n",
    "        classname = \"({}) {}\".format(i, classnames[i])\n",
    "        print(cm[i, :], classname)\n",
    "    # Print the class-numbers for easy reference.\n",
    "    class_numbers = [\" ({0})\".format(i) for i in range(num_classes)]\n",
    "    print(\"\".join(class_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_accuracy():\n",
    "    correct, pred = predict()\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(correct.mean(), correct.sum(), test_sz))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    plot_confusion_matrix(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 9.3% (933 / 10000)\n",
      "Confusion Matrix:\n",
      "[ 25 518   0 200   1   9 117   0  31  99] (0) airplane\n",
      "[ 41  83   0  53   4   7 185   0  82 545] (1) automobile\n",
      "[ 64 552   0 121   4   6 133   0  23  97] (2) bird\n",
      "[ 43 324   0 161   3   2 165   0  25 277] (3) cat\n",
      "[ 56 586   0  44   1   3 178   0   7 125] (4) deer\n",
      "[ 60 349   0 222  10   4 115   0   5 235] (5) dog\n",
      "[149 487   0  80   4  19  67   0  13 181] (6) frog\n",
      "[ 53 678   0  57   1   3 123   0  17  68] (7) horse\n",
      "[ 39 653   0  74   3   0 125   0  65  41] (8) ship\n",
      "[ 14 252   0  76   0  11 115   0   5 527] (9) truck\n",
      " (0) (1) (2) (3) (4) (5) (6) (7) (8) (9)\n"
     ]
    }
   ],
   "source": [
    "print_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:     50, Training Batch Accuracy:  39.1%\n",
      "Global Step:    100, Training Batch Accuracy:  57.0%\n",
      "Total time : 1.2875735759735107 seconds\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 57.1% (5709 / 10000)\n",
      "Confusion Matrix:\n",
      "[839   0   5   7   0  12   0   0 105  32] (0) airplane\n",
      "[419 177   3   5   0 134   0   0 126 136] (1) automobile\n",
      "[216   0 421  54   4  41  96   0 145  23] (2) bird\n",
      "[ 64   0   1 516   0 163 135   0  12 109] (3) cat\n",
      "[ 98   0   9   9 214 104  91   0  52 423] (4) deer\n",
      "[ 49   0   1  58   1 790  21   0   1  79] (5) dog\n",
      "[ 17   0   5  14   0  32 911   0  10  11] (6) frog\n",
      "[211   0  18  64  12  50   5   0 295 345] (7) horse\n",
      "[ 59   1   0   1   0   1   1   0 926  11] (8) ship\n",
      "[ 45   2   0   4   0   3   1   0  30 915] (9) truck\n",
      " (0) (1) (2) (3) (4) (5) (6) (7) (8) (9)\n"
     ]
    }
   ],
   "source": [
    "print_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
