{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3, linewidth=200, suppress=True)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split as train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import sklearn.metrics as skm\n",
    "from sklearn import svm\n",
    "from sklearn.externals import joblib\n",
    "import os, time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import toimage\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from library.datasets.cifar10 import CIFAR10\n",
    "from library.utils import file_utils\n",
    "from library.plot_tools import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_time = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_no = 1\n",
    "file_no = 3\n",
    "one_hot = False\n",
    "data_source = 'Website'\n",
    "train_validate_split = 0.2\n",
    "num_images_required = 1.0\n",
    "scale_method = 'StandardScaler'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp_hidden_size = (3072, 3072)\n",
    "mlp_iterations = 2000\n",
    "mlp_solver = 'adam'\n",
    "mlp_alpha = 1e-5\n",
    "early_stop=False\n",
    "param_name = 'exp_' + str(exp_no).zfill(3) + '_solver_' + mlp_solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_name = 'exp_' + str(exp_no).zfill(3) + '_solver_' + mlp_solver\n",
    "output_directory = '../logs/cifar10/' + str(file_no).zfill(3) + '_mlp_raw/' + 'exp_no_' + str(exp_no).zfill(3) + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load CIFAR 10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "cifar10 = CIFAR10(one_hot_encode=one_hot, num_images=num_images_required,\n",
    "                  train_validate_split=None, endian='little')\n",
    "cifar10.load_data(train=True, test=True, data_directory='./datasets/cifar10/')\n",
    "end = time.time()\n",
    "print('[ Step 0] Dataset loaded in %5.6f ms' %((end-start)*1000))\n",
    "print('Dataset size: ' + str(cifar10.train.data.shape))\n",
    "num_train_images = cifar10.train.data.shape[0]\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cifar10.plot_sample(plot_data=True, plot_test=True, fig_size=(7, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cifar10.plot_images(cifar10.train.data[:50, :], cifar10.train.class_names[:50], \n",
    "                    nrows=5, ncols=10, fig_size=(20,50), fontsize=35, convert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "if scale_method == 'StandardScaler':\n",
    "    ss = StandardScaler()\n",
    "elif scale_method == 'MinMaxScaler':\n",
    "    ss = MinMaxScaler()\n",
    "else:\n",
    "    ss = StandardScaler()\n",
    "data_images = ss.fit_transform(cifar10.train.data)\n",
    "test_images = ss.fit_transform(cifar10.test.data)\n",
    "end = time.time()\n",
    "print('[ Step 2] Dataset transformations done in %.6f ms' %((end-start)*1000))\n",
    "print('Training the classifier on %d images' % num_train_images)\n",
    "print('Dataset size: ' + str(cifar10.train.data.shape))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train test split of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_images, cifar10.train.class_labels, \n",
    "                                                    test_size=train_validate_split)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "print('Train set shape         : ' + str(X_train.shape))\n",
    "print('Train labels shape      : ' + str(y_train.shape))\n",
    "print('Validation set shape    : ' + str(X_test.shape))\n",
    "print('Validation labels shape : ' + str(y_test.shape))\n",
    "end = time.time()\n",
    "print('[ Step 3] Train-test split done in %.6f ms' %((end-start)*1000))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Initiate Multi Layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "clf = MLPClassifier(solver=mlp_solver, alpha=mlp_alpha, hidden_layer_sizes=mlp_hidden_size, random_state=1, \n",
    "                    max_iter=mlp_iterations, verbose=True, early_stopping=early_stop)\n",
    "print(clf)\n",
    "end = time.time()\n",
    "print('[ Step 4] Made the Multi layer perceptron classifier in %.6f ms' %((end-start)*1000))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate the MLP Model using the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "clf.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print('[ Step 5] Made the model in %.6f ms' %((end-start)*1000))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Write the obtained model to file for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "file_utils.mkdir_p(output_directory)\n",
    "model_output_path = output_directory + '03_' + param_name + '.pkl'\n",
    "joblib.dump(clf, model_output_path)\n",
    "end = time.time()\n",
    "print('[ Step 6] Write obtained model to %s in %.6f ms' %(model_output_path, ((end-start)*1000)))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Do the prediction on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test)\n",
    "labels = sorted(list(set(cifar10.train.class_labels)))\n",
    "print('Labels: ' + str(labels))\n",
    "plot.plot_confusion_matrix(y_test, y_predict, classes=cifar10.classes, fig_size=(8,6),\n",
    "                           normalize=True, title='Confusion matrix for validation set with SVC')\n",
    "end = time.time()\n",
    "print('[ Step 7] Make prediction on validation dataset in %.6f ms' %((end-start)*1000))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Generate the Classification report for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print('Classification report:')\n",
    "print(skm.classification_report(y_test, y_predict, target_names=cifar10.classes))\n",
    "validate_accuracy = skm.accuracy_score(y_test, y_predict, normalize=True)\n",
    "print('Validation accuracy score: ' + str(validate_accuracy))\n",
    "end = time.time()\n",
    "print('[ Step 8] Generating classification on validation dataset in %.6f ms' %((end-start)*1000))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Generate the predictions on test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "prediction_numbers = clf.predict(test_images)\n",
    "prediction_classes = []\n",
    "num_test_images = test_images.shape[0]\n",
    "for i in range(num_test_images):\n",
    "    prediction_classes.append(cifar10.classes[int(prediction_numbers[i])])\n",
    "end = time.time()\n",
    "print('[ Step 9] Make prediction on test dataset in %.6f ms' %((end-start)*1000))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cifar10.plot_images(cifar10.test.data[:50], cifar10.test.class_names[:50], cls_pred=prediction_classes[:50], \n",
    "                    nrows=5, ncols=10, fig_size=(20,50), fontsize=30, convert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Print the accuracy score of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "plot.plot_confusion_matrix(cifar10.test.class_labels, prediction_numbers, classes=cifar10.classes,\n",
    "                           normalize=True, title='Confusion matrix for test set with MLP with raw pixels')\n",
    "print(skm.classification_report(cifar10.test.class_labels, prediction_numbers, target_names=cifar10.classes))\n",
    "test_accuracy = skm.accuracy_score(cifar10.test.class_labels, prediction_numbers, normalize=True)\n",
    "print('Accuracy score on test data: ' + str(test_accuracy))\n",
    "end = time.time()\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print('Prediction done on %d images' %cifar10.test.data.shape[0])\n",
    "print('Accuracy of the classifier: %.4f' %clf.score(test_images, cifar10.test.class_labels))\n",
    "end = time.time()\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Write the predictions to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "indices = np.arange(1, cifar10.test.data.shape[0]+1)\n",
    "predictions = np.column_stack((indices, prediction_classes))\n",
    "file_utils.mkdir_p(output_directory)\n",
    "output_csv_file = output_directory + '03_' + param_name + '.csv'\n",
    "column_names = ['id', 'label']\n",
    "predict_test_df = pd.DataFrame(data=predictions, columns=column_names)\n",
    "predict_test_df.to_csv(output_csv_file, index=False)\n",
    "end = time.time()\n",
    "print('[ Step 11] Writing the test data to file: %s in %.6f ms' %(output_csv_file, (end-start)*1000))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Code took %.6f s to run on training with %d examples' % (total_time,num_train_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print parameters for record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('| %d | ' %exp_no, end='')\n",
    "print('%d | '%num_train_images, end='')\n",
    "print('Hidden layers size = %s, Max. Iterations: %d, Alpha: %.6f, Solver: %s, Random state: 1 | ' \n",
    "      %(str(mlp_hidden_size), mlp_iterations, mlp_alpha, mlp_solver), end='')\n",
    "print('[Link](%s) | ' %output_csv_file, end='')\n",
    "print('%.4f | ' %validate_accuracy, end='')\n",
    "print('%.4f | ' %test_accuracy, end='')\n",
    "print('%s | ' %data_source, end='')\n",
    "print('[Link](%s) |' %model_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Write the notebook to html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_HTML(read_file, output_file):\n",
    "    from nbconvert import HTMLExporter\n",
    "    import codecs\n",
    "    import nbformat\n",
    "    exporter = HTMLExporter()\n",
    "    output_notebook = nbformat.read(read_file, as_version=4)\n",
    "    print()\n",
    "    output, resources = exporter.from_notebook_node(output_notebook)\n",
    "    codecs.open(output_file, 'w', encoding='utf-8').write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "var notebook = IPython.notebook\n",
    "notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_file = './' + theNotebook + '.ipynb'\n",
    "output_file = output_directory + str(file_no).zfill(2) + '_exp_no_' + str(exp_no) + '_' + theNotebook + '.html'\n",
    "print('Current file: ' + str(current_file))\n",
    "print('Output file: ' + str(output_file))\n",
    "file_utils.mkdir_p(output_directory) \n",
    "output_HTML(current_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Code took %.6f s to run on training with %d examples' % (total_time,num_train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
