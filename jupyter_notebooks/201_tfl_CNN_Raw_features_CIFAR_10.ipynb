{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.data_utils import shuffle, to_categorical\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "from tflearn.data_augmentation import ImageAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, time\n",
    "import numpy as np\n",
    "sys.path.insert(0, '../')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from library.datasets import cifar10\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from library.utils import file_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from library.plot_tools import plot\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp_no = 55\n",
    "file_no = 20\n",
    "dataset = 'cifar10'\n",
    "train_epochs = 20\n",
    "tensorboard_verbose = 3\n",
    "one_hot = True\n",
    "make_image = True\n",
    "mode='rgb_flot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing tensorboard logs to ../logs/cifar10/20_tfl_cnn_models/exp_no_055/tflearn_cnn_classifier.ckpt\n",
      "view logs by running tensorboard: \"tensorboard --logdir='./20_tf_cnn/' --port 61111\"\n"
     ]
    }
   ],
   "source": [
    "output_directory = '../logs/cifar10/' + str(file_no).zfill(2) + '_tfl_cnn_models/' + 'exp_no_' + str(exp_no).zfill(3) + '/'\n",
    "file_utils.mkdir_p(output_directory)\n",
    "ck_path = output_directory + 'model.tfl.ckpt'\n",
    "log_file = output_directory + 'tflearn_cnn_classifier.ckpt'\n",
    "model_output_path = output_directory + 'model.tflearn'\n",
    "print('Writing tensorboard logs to %s' % log_file)\n",
    "print('view logs by running tensorboard: ', end='')\n",
    "print('\\\"tensorboard --logdir=\\'./20_tf_cnn/\\' --port 61111\\\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_time = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.1: Load CIFAR 10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CIFAR 10 Dataset\n",
      "Downloading and extracting CIFAR 10 file\n",
      "MD5sum of the file: ./datasets/cifar10/cifar-10.tar.gz is verified\n",
      "Loading 50000 train images\n",
      "Loading CIFAR 10 Training Dataset\n",
      "Reading unpicked data file: ./datasets/cifar10/cifar-10-batches/data_batch_1\n",
      "Reading unpicked data file: ./datasets/cifar10/cifar-10-batches/data_batch_2\n",
      "Reading unpicked data file: ./datasets/cifar10/cifar-10-batches/data_batch_3\n",
      "Reading unpicked data file: ./datasets/cifar10/cifar-10-batches/data_batch_4\n",
      "Reading unpicked data file: ./datasets/cifar10/cifar-10-batches/data_batch_5\n",
      "Loading 10000 test images\n",
      "Loading CIFAR 10 Test Dataset\n",
      "Unpickling test file: ./datasets/cifar10/cifar-10-batches/test_batch\n",
      "Reading unpicked test file: ./datasets/cifar10/cifar-10-batches/test_batch\n",
      "Loaded CIFAR 10 Dataset in 3.8522 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_dataset = cifar10.CIFAR10(one_hot_encode=one_hot, num_images=1.0, image_mode=mode,\n",
    "                                  train_validate_split=None, endian='little')\n",
    "cifar10_dataset.load_data(train=True, test=True, data_directory='./datasets/cifar10/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.2: Make test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = cifar10_dataset.train.images\n",
    "Y = cifar10_dataset.train.one_hot_labels\n",
    "X_test = cifar10_dataset.test.images\n",
    "Y_test = cifar10_dataset.test.one_hot_labels\n",
    "X_train, X_validate, Y_train, Y_validate = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.3: Print image shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape        : (50000, 32, 32, 3)\n",
      "Train labels shape      : (50000, 10)\n",
      "Validation data shape   : (10000, 32, 32, 3)\n",
      "Validation labels shape : (10000, 10)\n",
      "Test data shape         : (10000, 32, 32, 3)\n",
      "Test labels shape       : (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('Train data shape        :', X.shape)\n",
    "print('Train labels shape      :', Y.shape)\n",
    "print('Validation data shape   :', X_validate.shape)\n",
    "print('Validation labels shape :', Y_validate.shape)\n",
    "print('Test data shape         :', X_test.shape)\n",
    "print('Test labels shape       :', Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.4 Display train and test images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cifar10_dataset.plot_sample(plot_data=True, plot_test=True, fig_size=(7, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.5 Display train images with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cifar10_dataset.plot_images(cifar10_dataset.train.data[:50, :], cifar10_dataset.train.class_names[:50], \n",
    "#                             nrows=5, ncols=10, fig_size=(20,50), fontsize=35, convert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 1.6 Image augmentation and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Real-time data preprocessing\n",
    "img_prep = ImagePreprocessing()\n",
    "img_prep.add_featurewise_zero_center()\n",
    "img_prep.add_featurewise_stdnorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Real-time data augmentation\n",
    "img_aug = ImageAugmentation()\n",
    "img_aug.add_random_flip_leftright()\n",
    "img_aug.add_random_rotation(max_angle=25.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#img_aug.add_random_crop([32, 32], padding=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = input_data(shape=[None, 32, 32, 3], data_preprocessing=img_prep, data_augmentation=img_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Model Convolutional Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# accuracy== 0.80589\n",
    "# network = conv_2d(network, 32, 3, activation='relu')\n",
    "# network = max_pool_2d(network, 2)\n",
    "# network = conv_2d(network, 128, 3, activation='relu')\n",
    "# network = max_pool_2d(network, 2)\n",
    "# network = conv_2d(network, 512, 3, activation='relu')\n",
    "# network = max_pool_2d(network, 2)\n",
    "# network = fully_connected(network, 1024, activation='relu')\n",
    "# network = dropout(network, 0.5)\n",
    "# network = fully_connected(network, 10, activation='softmax')\n",
    "# network = regression(network, optimizer='adam',\n",
    "#                      loss='categorical_crossentropy',\n",
    "#                      learning_rate=0.001)\n",
    "\n",
    "\n",
    "#################################################################\n",
    "# accuracy == 0.79359999999999997\n",
    "\n",
    "# network = conv_2d(network, 32, 3, activation='relu')\n",
    "# network = max_pool_2d(network, 2)\n",
    "# network = conv_2d(network, 64, 3, activation='relu')\n",
    "# network = max_pool_2d(network, 2)\n",
    "# network = conv_2d(network, 128, 3, activation='relu')\n",
    "# network = max_pool_2d(network, 2)\n",
    "# network = conv_2d(network, 256, 3, activation='relu')\n",
    "# network = max_pool_2d(network, 2)\n",
    "# network = conv_2d(network, 512, 3, activation='relu')\n",
    "# network = max_pool_2d(network, 2)\n",
    "# network = fully_connected(network, 1024, activation='relu')\n",
    "# network = dropout(network, 0.5)\n",
    "# network = fully_connected(network, 2048, activation='relu')\n",
    "# network = dropout(network, 0.5)\n",
    "# network = fully_connected(network, 10, activation='softmax')\n",
    "# network = regression(network, optimizer='adam',\n",
    "#                      loss='categorical_crossentropy',\n",
    "#                      learning_rate=0.001)\n",
    "\n",
    "\n",
    "##################################################################\n",
    "\n",
    "#ex3==0.81089999999999995   itern 100 without crop\n",
    "\n",
    "# iteration 5 without crop 0.73309999999999997\n",
    "# iteration 5 with crop 0.76\n",
    "# network = conv_2d(network, 32, 3, activation='relu')\n",
    "# network = max_pool_2d(network, 2)\n",
    "# network = conv_2d(network, 64, 3, activation='relu')\n",
    "# network = conv_2d(network, 64, 3, activation='relu')\n",
    "# network = max_pool_2d(network, 2)\n",
    "# network = fully_connected(network, 512, activation='relu')\n",
    "# network = dropout(network, 0.5)\n",
    "# network = fully_connected(network, 10, activation='softmax')\n",
    "# network = regression(network, optimizer='adam',\n",
    "#                       loss='categorical_crossentropy',\n",
    "#                       learning_rate=0.001)\n",
    "\n",
    "\n",
    "network = conv_2d(network, 32, 3, activation='relu')\n",
    "network = conv_2d(network, 32, 3, activation='relu')\n",
    "network = conv_2d(network, 32, 3, activation='relu')\n",
    "network = conv_2d(network, 32, 3, activation='relu')\n",
    "network = max_pool_2d(network, 2)\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "network = max_pool_2d(network, 2)\n",
    "network = conv_2d(network, 128, 3, activation='relu')\n",
    "network = conv_2d(network, 128, 3, activation='relu')\n",
    "network = conv_2d(network, 128, 3, activation='relu')\n",
    "network = conv_2d(network, 128, 3, activation='relu')\n",
    "\n",
    "network = max_pool_2d(network, 2)\n",
    "network = fully_connected(network, 512, activation='relu')\n",
    "network = dropout(network, 0.5)\n",
    "network = fully_connected(network, 10, activation='softmax')\n",
    "network = regression(network, optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model = tflearn.DNN(network, tensorboard_verbose=tensorboard_verbose,\n",
    "                    tensorboard_dir=log_file,checkpoint_path=ck_path)\n",
    "model.fit(X_train, Y_train, n_epoch=train_epochs, \n",
    "          shuffle=True,snapshot_epoch=True, validation_set=(X_validate, Y_validate),\n",
    "          show_metric=True, batch_size=96, run_id='cifar10_cnn')\n",
    "end = time.time()\n",
    "print('Model fit done in %s' %(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Write the obtained Model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save(model_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_accuracy = model.evaluate(cifar10_dataset.test.images, cifar10_dataset.test.one_hot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predict_raw = model.predict(X_validate)\n",
    "y_predict = np.argmax(y_predict_raw, axis=1, out=None)\n",
    "y_val = np.argmax(Y_validate, axis=1, out=None)\n",
    "labels = sorted(list(set(cifar10_dataset.train.class_labels)))\n",
    "print('Labels: ' + str(labels))\n",
    "plot.plot_confusion_matrix(y_val,y_predict, classes=cifar10_dataset.classes, fig_size=(8,6),\n",
    "                              normalize=True, title='Confusion matrix for validation set with CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print('Classification report:')\n",
    "print(skm.classification_report(y_val, y_predict, target_names=cifar10_dataset.classes))\n",
    "validate_accuracy = skm.accuracy_score(y_val, y_predict, normalize=True)\n",
    "print('Validation accuracy score: ' + str(validate_accuracy))\n",
    "end = time.time()\n",
    "print('[ Step 4] Generating classification on validation dataset in %.6f ms' % ((end-start)*1000))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_raw = model.predict(X_test)\n",
    "y_predict = np.argmax(y_predict_raw, axis=1, out=None)\n",
    "y_val = np.argmax(Y_test, axis=1, out=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cifar10_dataset.plot_images(cifar10_dataset.test.data[:50], cifar10_dataset.test.class_names[:50], \n",
    "                            cls_pred=y_val[:50], nrows=5, ncols=10, fig_size=(20,50), fontsize=30, convert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = sorted(list(set(cifar10_dataset.train.class_labels)))\n",
    "print('Labels: ' + str(labels))\n",
    "plot.plot_confusion_matrix(y_val, y_predict, classes=cifar10_dataset.classes, fig_size=(8,6),\n",
    "                           normalize=True, title='Confusion matrix for validation set with CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print('Classification report:')\n",
    "print(skm.classification_report(y_val, y_predict, target_names=cifar10_dataset.classes))\n",
    "validate_accuracy = skm.accuracy_score(y_val, y_predict, normalize=True)\n",
    "print('Test accuracy score: ' + str(validate_accuracy))\n",
    "end = time.time()\n",
    "print('[ Step 5] Generating classification on validation dataset in %.6f ms' %((end-start)*1000))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 : Write the predictions to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "indices = np.arange(1, len(Y_test)+1)\n",
    "predictions = np.column_stack((indices, y_val))\n",
    "output_csv_file = output_directory + str(exp_no).zfill(3) + '.csv'\n",
    "column_names = ['id', 'label']\n",
    "predict_test_df = pd.DataFrame(data=predictions, columns=column_names)\n",
    "predict_test_df.to_csv(output_csv_file, index=False)\n",
    "end = time.time()\n",
    "print('[ Step 11] Writing the test data to file: %s in %.6f ms' %(output_csv_file, (end-start)*1000))\n",
    "total_time += (end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 : Write the notebook to HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_HTML(read_file, output_file):\n",
    "    from nbconvert import HTMLExporter\n",
    "    import codecs\n",
    "    import nbformat\n",
    "    exporter = HTMLExporter()\n",
    "    output_notebook = nbformat.read(read_file, as_version=4)\n",
    "    print()\n",
    "    output, resources = exporter.from_notebook_node(output_notebook)\n",
    "    codecs.open(output_file, 'w', encoding='utf-8').write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "var notebook = IPython.notebook\n",
    "notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_file = './' + theNotebook + '.ipynb'\n",
    "output_file = output_directory + str(file_no).zfill(3) + '_exp_no_' + str(exp_no).zfill(3) + '_' + theNotebook + '.html'\n",
    "print('Current file: ' + str(current_file))\n",
    "print('Output file: ' + str(output_file))\n",
    "file_utils.mkdir_p(output_directory) \n",
    "output_HTML(current_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
